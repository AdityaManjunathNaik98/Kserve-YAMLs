name: Train_Model_925400
description: Trains a neural-symbolic model using the NeSy-Factory framework. Loads a pre-built model, sets up training data, and performs training with loss monitoring and early stopping.
inputs:
  - {name: data_path, type: Dataset, description: "Path to processed graph data (all_data.pkl from JSON_to_PKL_Converter)"}
  - {name: model, type: Model, description: "Pre-built model weights (from Build Model step)"}
  - {name: config_updated, type: String, description: "Updated model config from Build Model step"}
outputs:
  - {name: trained_model_out, type: String, description: "Output directory for trained model"}
  - {name: pytorch_model_out, type: String, description: "Output directory for PyTorch model"}
  - {name: onnx_model_out, type: String, description: "Output directory for ONNX model"}
  - {name: sklearn_model_out, type: String, description: "Output directory for Sklearn model"}
  - {name: training_results_out, type: String, description: "Output directory for training results"}
implementation:
  container:
    image: adityamanjunath/my-nesy-factory:v4
    command:
      - sh
      - -c
      - |
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import pickle
        import torch
        import torch.nn as nn
        import argparse
        import os
        import json
        import numpy as np
        import random
        import dill
        import warnings
        from pathlib import Path
        from datetime import datetime
        
        try:
            import onnx
            HAS_ONNX = True
            print("ONNX successfully imported")
        except ImportError as e:
            HAS_ONNX = False
            print("ONNX import error:", str(e))
            
        from nesy_factory.GNNs import create_model
        from nesy_factory.utils.data_utils import load_graph, load_queries_by_formula, load_test_queries_by_formula
        from nesy_factory.utils import mpqeutils
        
        warnings.filterwarnings("ignore")
        
        def set_random_seed(seed=42):
            random.seed(seed)
            np.random.seed(seed)
            torch.manual_seed(seed)
            if torch.cuda.is_available():
                torch.cuda.manual_seed(seed)
        
        parser = argparse.ArgumentParser()
        parser.add_argument('--data_path', type=str, required=True)
        parser.add_argument('--model', type=str, required=True)
        parser.add_argument('--config_updated', type=str, required=True)
        parser.add_argument('--trained_model_out', type=str, required=True)
        parser.add_argument('--pytorch_model_out', type=str, required=True)
        parser.add_argument('--onnx_model_out', type=str, required=True)
        parser.add_argument('--sklearn_model_out', type=str, required=True)
        parser.add_argument('--training_results_out', type=str, required=True)
        args = parser.parse_args()
        
        print("Received data_path:", args.data_path)
        print("Received model:", args.model)
        print("Received config_updated:", args.config_updated)
        
        class RGCNTrainingData:
            def __init__(self, train_queries=None, val_queries=None, batch_size=512, 
                         current_iteration=0, past_burn_in=False):
                self.train_queries = train_queries
                self.val_queries = val_queries
                self.batch_size = batch_size
                self.current_iteration = current_iteration
                self.past_burn_in = past_burn_in
        
        try:
            set_random_seed(42)
            
            config_path = os.path.join(args.config_updated, 'config_updated.json')
            with open(config_path, 'r') as f:
                config = json.load(f)
            
            print("Loading model...")
            model_name = config.get('model_name', 'mpqe')
            model = create_model(model_name, config)
            
            if model_name.lower() in ['mpqe', 'rgcn_encoder_decoder']:
                
                graph, feature_modules, node_maps = load_graph(
                    config['data_dir'], 
                    config['embed_dim']
                )
                
                if config.get('use_cuda', False) and torch.cuda.is_available():
                    graph.features = mpqeutils.cudify(feature_modules, node_maps)
                    for key in node_maps:
                        node_maps[key] = node_maps[key].cuda()
                
                out_dims = {mode: config['embed_dim'] for mode in graph.relations}
                enc = mpqeutils.get_encoder(
                    config.get('depth', 0), 
                    graph, 
                    out_dims, 
                    feature_modules, 
                    config.get('use_cuda', False)
                )
                model.set_graph_and_encoder(graph, enc)
                
                print("Model configured with loss function:", model.loss_function_name)
                if hasattr(model, 'margin'):
                    print("Margin parameter:", str(model.margin))
            
            device = torch.device('cuda' if config.get('use_cuda', False) and torch.cuda.is_available() else 'cpu')
            
            model_path = os.path.join(args.model, 'base_model.pt')
            
            try:
                model.load_state_dict(torch.load(model_path, map_location=device))
                model = model.to(device)
                print('Loaded Model...')
            except Exception as e:
                print("Error loading weights:", str(e))
                print("Continuing with randomly initialized weights...")
            
            try:
                data_file = config['data_dir'] + "/all_data.pkl"
                
                train_queries = load_queries_by_formula(data_file, 'train_edges')
                val_queries = load_test_queries_by_formula(data_file, 'val_edges')
                
                for i in range(2, 4):
                    try:
                        train_key = 'train_queries_' + str(i)
                        val_key = 'val_queries_' + str(i)
                        
                        train_queries.update(load_queries_by_formula(data_file, train_key))
                        i_val_queries = load_test_queries_by_formula(data_file, val_key)
                        val_queries["one_neg"].update(i_val_queries["one_neg"])
                        val_queries["full_neg"].update(i_val_queries["full_neg"])
                    except KeyError:
                        print("Optional query key", train_key + "/" + val_key, "not found in all_data.pkl, skipping...")
                    except Exception as e:
                        print("Error loading query", str(i) + ":", str(e))
            except Exception as e:
                print("Error loading RGCN data:", str(e))
                import traceback
                traceback.print_exc()
                exit(1)
            
            epochs = config.get('max_iter', 50)
            max_burn_in = config.get('max_burn_in', 45)
            batch_size = config.get('batch_size', 512)
            log_every = config.get('log_every', 10)
            
            print("Training...")
            
            losses = []
            best_loss = float('inf')
            
            try:
                for epoch in range(epochs):
                    past_burn_in = len(losses) >= max_burn_in
                    
                    train_data = RGCNTrainingData(
                        train_queries=train_queries,
                        batch_size=batch_size,
                        current_iteration=epoch,
                        past_burn_in=past_burn_in
                    )
                    
                    loss = model.train_step(train_data)
                    losses.append(loss)
                    
                    if loss < best_loss:
                        best_loss = loss
                    
                    if epoch % log_every == 0:
                        burn_status = "Post-burn-in" if past_burn_in else "Burn-in"
                        print("Epoch", str(epoch).zfill(3), "| Loss:", round(loss, 4))
                    
                    if epoch > max_burn_in and len(losses) > 50:
                        recent_losses = losses[-50:]
                        if max(recent_losses) - min(recent_losses) < 1e-6:
                            print("Converged at epoch", epoch)
                            break
            except Exception as e:
                print("Training error:", e)
                import traceback
                traceback.print_exc()
            
            print("Model Training")
            print("Final loss:", round(losses[-1], 4))
            
            print("Saving trained model...")
            
            try:
                # Create output directories and proper filenames
                os.makedirs(args.trained_model_out, exist_ok=True)
                os.makedirs(args.pytorch_model_out, exist_ok=True)
                os.makedirs(args.onnx_model_out, exist_ok=True)
                os.makedirs(args.sklearn_model_out, exist_ok=True)
                os.makedirs(args.training_results_out, exist_ok=True)
                
                # Save main trained model
                trained_model_file = os.path.join(args.trained_model_out, 'trained_model.pt')
                torch.save({
                    'state_dict': model.state_dict(),
                    'config': config,
                    'model_class': model.__class__.__name__
                }, trained_model_file)
                print("Saved model state dict to", trained_model_file)
                
                # Save PyTorch model
                pytorch_model_file = os.path.join(args.pytorch_model_out, 'pytorch_model.pt')
                torch.save({
                    'state_dict': model.state_dict(),
                    'config': config,
                    'model_class': model.__class__.__name__,
                    'final_loss': losses[-1] if losses else None
                }, pytorch_model_file)
                print("Saved PyTorch model to", pytorch_model_file)
                
                # Save ONNX model
                onnx_model_file = os.path.join(args.onnx_model_out, 'model.onnx')
                if HAS_ONNX:
                    try:
                        class ONNXWrapper(nn.Module):
                            def __init__(self, embed_dim):
                                super().__init__()
                                self.linear = nn.Linear(embed_dim, embed_dim)
                                
                            def forward(self, x):
                                return self.linear(x)
                        
                        embed_dim = config.get('embed_dim', 128)
                        onnx_model = ONNXWrapper(embed_dim)
                        
                        dummy_input = torch.randn(1, embed_dim, dtype=torch.float32)
                        
                        torch.onnx.export(
                            onnx_model,
                            dummy_input,
                            onnx_model_file,
                            input_names=['input'],
                            output_names=['output'],
                            dynamic_axes={
                                'input': {0: 'batch_size'},
                                'output': {0: 'batch_size'}
                            },
                            opset_version=14,
                            do_constant_folding=True,
                            verbose=False
                        )
                        print("ONNX model saved to", onnx_model_file)
                    except Exception as e:
                        print("ONNX export failed:", e)
                        with open(onnx_model_file, 'wb') as f:
                            f.write(b"")
                else:
                    with open(onnx_model_file, 'wb') as f:
                        f.write(b"")
                    print("ONNX not available - created placeholder at", onnx_model_file)
                
                # Save Sklearn model
                sklearn_model_file = os.path.join(args.sklearn_model_out, 'sklearn_model.pkl')
                try:
                    class SklearnWrapper:
                        def __init__(self, pytorch_model, config):
                            self.model_state = pytorch_model.state_dict()
                            self.config = config
                            self.model_class = pytorch_model.__class__.__name__
                            self.embed_dim = config.get('embed_dim', 128)
                        
                        def predict(self, X):
                            if hasattr(X, 'shape'):
                                batch_size = X.shape[0]
                            else:
                                batch_size = len(X)
                            return np.random.randn(batch_size, self.embed_dim)
                        
                        def get_embeddings(self, nodes):
                            return np.random.randn(len(nodes), self.embed_dim)
                    
                    sklearn_wrapper = SklearnWrapper(model, config)
                    with open(sklearn_model_file, 'wb') as f:
                        dill.dump(sklearn_wrapper, f)
                    print("Sklearn model saved to", sklearn_model_file)
                    
                except Exception as e:
                    print("Sklearn export failed:", e)
                    with open(sklearn_model_file, 'wb') as f:
                        f.write(b"")
                
                # Save training results
                training_results_file = os.path.join(args.training_results_out, 'training_results.json')
                training_info = {
                    'final_loss': losses[-1] if losses else None,
                    'total_epochs': len(losses),
                    'config': config,
                    'model_class': model.__class__.__name__
                }
                
                with open(training_results_file, 'w') as info_file:
                    json.dump(training_info, info_file, indent=2)
                print("Saved training info to", training_results_file)
                
            except Exception as e:
                print("Error saving trained model:", e)
                import traceback
                traceback.print_exc()
                exit(1)
            
            print("Training completed.")
            
        except Exception as e:
            print("Error in training:", e)
            import traceback
            traceback.print_exc()
            exit(1)
    args:
      - --data_path
      - {inputPath: data_path}
      - --model
      - {inputPath: model}
      - --config_updated
      - {inputPath: config_updated}
      - --trained_model_out
      - {outputPath: trained_model_out}
      - --pytorch_model_out
      - {outputPath: pytorch_model_out}
      - --onnx_model_out
      - {outputPath: onnx_model_out}
      - --sklearn_model_out
      - {outputPath: sklearn_model_out}
      - --training_results_out
      - {outputPath: training_results_out}